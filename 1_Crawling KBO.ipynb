{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Crawling KBO\n",
    "\n",
    "- Website : http://www.koreabaseball.com\n",
    "- Object : 2015 season /  all 10 teams in KBO League\n",
    "- Player game stats\n",
    "    - hitter\n",
    "    - pitcher\n",
    "    - defense\n",
    "    - runner\n",
    "    \n",
    "- Player basic info\n",
    "    - salary and other basic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make api delay term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_delay_term = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Players' stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# crawling_hitter_basic_stats\n",
    "def crawling_hitter_basic(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    \n",
    "    # connect url\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "\n",
    "    # make empty dataframe\n",
    "    hitter_basic_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'avg', 'g', 'pa', 'ab', 'r', 'h', '2b',\n",
    "        '3b', 'hr', 'tb', 'rbi', 'sac', 'sf'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "\n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'g' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'pa' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'ab' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'r' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'h' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                '2b' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                '3b' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'hr' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'tb' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'rbi' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'sac' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'sf' : element.find_elements_by_css_selector('td')[15].text,\n",
    "            }\n",
    "            hitter_basic_df.loc[len(hitter_basic_df)] = tmp_dict\n",
    "    \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'g' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'pa' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'ab' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'r' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'h' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    '2b' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    '3b' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'hr' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'tb' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'rbi' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'sac' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'sf' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                }\n",
    "                hitter_basic_df.loc[len(hitter_basic_df)] = tmp_dict\n",
    "                \n",
    "    return hitter_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_hitter_detail_stats\n",
    "def crawling_hitter_detail(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/HitterBasic/Detail1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    hitter_detail_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'avg', 'xbh', 'go', 'ao', 'go/ao', 'gw rbi',\n",
    "        'bb/k', 'p/pa', 'isop', 'xr', 'gpa'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "    \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'xbh' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'go' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'ao' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'go/ao' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'gw rbi' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'bb/k' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'p/pa' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'isop' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'xr' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'gpa' : element.find_elements_by_css_selector('td')[13].text,\n",
    "            }\n",
    "            hitter_detail_df.loc[len(hitter_detail_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'xbh' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'go' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'ao' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'go/ao' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'gw rbi' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'bb/k' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'p/pa' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'isop' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'xr' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'gpa' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                }\n",
    "                hitter_detail_df.loc[len(hitter_detail_df)] = tmp_dict\n",
    "                \n",
    "    return hitter_detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_pitcher_basic\n",
    "def crawling_pitcher_basic(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    pitcher_basic_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'ERA', 'G', 'W', 'L', 'SV', 'HLD', 'WPCT',\n",
    "        'IP', 'H', 'HR', 'BB', 'HBP', 'SO', 'R', 'ER', 'WHIP'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'W' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'L' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'SV' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'HLD' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'WPCT' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'IP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'H' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'HR' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'BB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'HBP' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'SO' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                'R' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                'ER' : element.find_elements_by_css_selector('td')[17].text,\n",
    "                'WHIP' : element.find_elements_by_css_selector('td')[18].text,\n",
    "            }\n",
    "            pitcher_basic_df.loc[len(pitcher_basic_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'W' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'L' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'SV' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'HLD' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'WPCT' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'IP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'H' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'HR' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'BB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'HBP' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'SO' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                    'R' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                    'ER' : element.find_elements_by_css_selector('td')[17].text,\n",
    "                    'WHIP' : element.find_elements_by_css_selector('td')[18].text,\n",
    "                }\n",
    "                pitcher_basic_df.loc[len(pitcher_basic_df)] = tmp_dict\n",
    "        \n",
    "    return pitcher_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_pitcher_detail\n",
    "def crawling_pitcher_detail(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/PitcherBasic/Detail1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    pitcher_detail_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'ERA', 'GS', 'Wgs', 'Wgr', 'GF', 'SVO', 'TS',\n",
    "        'GDP', 'GO', 'AO', 'GO/AO'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'GS' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'Wgs' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'Wgr' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'GF' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'SVO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'TS' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'GDP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'GO' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'AO' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'GO/AO' : element.find_elements_by_css_selector('td')[13].text,\n",
    "            }\n",
    "            pitcher_detail_df.loc[len(pitcher_detail_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'GS' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'Wgs' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'Wgr' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'GF' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'SVO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'TS' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'GDP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'GO' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'AO' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'GO/AO' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                }\n",
    "                pitcher_detail_df.loc[len(pitcher_detail_df)] = tmp_dict\n",
    "    return pitcher_detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_defense\n",
    "def crawling_defense(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 14\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 2002 ~ 14 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.Firefox()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/Defense/Basic.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    defense_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'POS', 'G', 'GS', 'IP', 'E', 'PKO', 'PO',\n",
    "        'A', 'DP', 'FPCT', 'PB', 'SB', 'CS', 'CS%'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'POS' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'GS' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'IP' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'E' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'PKO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'PO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'A' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'DP' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'FPCT' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'PB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'SB' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'CS' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                'CS%' : element.find_elements_by_css_selector('td')[16].text,\n",
    "            }\n",
    "            defense_df.loc[len(defense_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'POS' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'GS' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'IP' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'E' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'PKO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'PO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'A' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'DP' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'FPCT' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'PB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'SB' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'CS' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                    'CS%' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                }\n",
    "                defense_df.loc[len(defense_df)] = tmp_dict\n",
    "\n",
    "    return defense_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_runner\n",
    "def crawling_runner(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 2002 ~ 14 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/Runner/Basic.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    runner_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'G', 'SBA', 'SB', 'CS', 'SB%', 'OOB',\n",
    "        'PKO'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'SBA' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'SB' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'CS' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'SB%' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'OOB' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'PKO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "            }\n",
    "            runner_df.loc[len(runner_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'SBA' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'SB' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'CS' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'SB%' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'OOB' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'PKO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                }\n",
    "                runner_df.loc[len(runner_df)] = tmp_dict\n",
    "\n",
    "    return runner_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Players' Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save player url\n",
    "def get_players_url(season_id, team_id):\n",
    "    # connect url\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "                find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "                find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "    \n",
    "    # make empty dataframe\n",
    "    url_df = pd.DataFrame(columns=['url'])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "    \n",
    "        for element in elements:\n",
    "            tmp_dict = {\n",
    "                \"url\" : element.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "                }\n",
    "            url_df.loc[len(url_df)] = tmp_dict\n",
    "            \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict = {\n",
    "                    \"url\" : element.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "                    }\n",
    "                url_df.loc[len(url_df)] = tmp_dict\n",
    "            \n",
    "    return url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawling_player_info(season_id, team_id):\n",
    "    # get each player's url\n",
    "    url_df = get_players_url(season_id, team_id)\n",
    "    \n",
    "    # drop the retired players\n",
    "    is_retired = url_df['url'].str.contains(\"Retire\") == True\n",
    "    url_df = url_df.drop(url_df.index[is_retired]).reset_index()\n",
    "    print(\"get url_df successfully\")\n",
    "    \n",
    "    # make empty dataframe\n",
    "    player_info_df = pd.DataFrame(columns=[\n",
    "                    \"p_number\", \"name\", \"salary\"\n",
    "            ])\n",
    "    driver1 = webdriver.PhantomJS()\n",
    "    \n",
    "    # connect each url & scrap player info\n",
    "    for number in range(0, len(url_df)):\n",
    "        player_url = url_df['url'][number]\n",
    "        driver1.get(player_url)\n",
    "        time.sleep(api_delay_term)\n",
    "        \n",
    "        player_info = driver1.find_elements_by_css_selector(\".player_basic ul li\")\n",
    "\n",
    "        tmp_dict = {\n",
    "                    \"p_number\" : player_url.split(\"=\")[1],\n",
    "                    \"name\" : player_info[0].text.split(\": \")[1],\n",
    "                    \"salary\" : player_info[7].text.split(\": \")[1],\n",
    "                    }\n",
    "        player_info_df.loc[len(player_info_df)] = tmp_dict\n",
    "\n",
    "    return player_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get url_df successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_number</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74339</td>\n",
       "      <td>유한준</td>\n",
       "      <td>60000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65399</td>\n",
       "      <td>허정협</td>\n",
       "      <td>3000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61366</td>\n",
       "      <td>홍성갑</td>\n",
       "      <td>3200만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73342</td>\n",
       "      <td>이택근</td>\n",
       "      <td>50000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61353</td>\n",
       "      <td>고종욱</td>\n",
       "      <td>7700만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77564</td>\n",
       "      <td>김민성</td>\n",
       "      <td>22000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78168</td>\n",
       "      <td>서건창</td>\n",
       "      <td>26000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74215</td>\n",
       "      <td>윤석민</td>\n",
       "      <td>16000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64300</td>\n",
       "      <td>김하성</td>\n",
       "      <td>16000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79130</td>\n",
       "      <td>강지광</td>\n",
       "      <td>2700만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63360</td>\n",
       "      <td>장시윤</td>\n",
       "      <td>3300만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>79365</td>\n",
       "      <td>박동원</td>\n",
       "      <td>14000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62332</td>\n",
       "      <td>김재현</td>\n",
       "      <td>4400만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76368</td>\n",
       "      <td>유재신</td>\n",
       "      <td>6000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65357</td>\n",
       "      <td>송성문</td>\n",
       "      <td>3000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79356</td>\n",
       "      <td>박헌도</td>\n",
       "      <td>8000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>76322</td>\n",
       "      <td>유선정</td>\n",
       "      <td>3900만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61363</td>\n",
       "      <td>문우람</td>\n",
       "      <td>9000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79300</td>\n",
       "      <td>김지수</td>\n",
       "      <td>5500만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73606</td>\n",
       "      <td>서동욱</td>\n",
       "      <td>5800만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64346</td>\n",
       "      <td>임병욱</td>\n",
       "      <td>4000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>79334</td>\n",
       "      <td>장영석</td>\n",
       "      <td>3300만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>63339</td>\n",
       "      <td>김민준</td>\n",
       "      <td>2700만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>65343</td>\n",
       "      <td>김택형</td>\n",
       "      <td>4400만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72749</td>\n",
       "      <td>마정길</td>\n",
       "      <td>20000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60336</td>\n",
       "      <td>문성현</td>\n",
       "      <td>11000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75321</td>\n",
       "      <td>손승락</td>\n",
       "      <td>70000만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>62363</td>\n",
       "      <td>한현희</td>\n",
       "      <td>30000만원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_number name   salary\n",
       "0     74339  유한준  60000만원\n",
       "1     65399  허정협   3000만원\n",
       "2     61366  홍성갑   3200만원\n",
       "3     73342  이택근  50000만원\n",
       "4     61353  고종욱   7700만원\n",
       "5     77564  김민성  22000만원\n",
       "6     78168  서건창  26000만원\n",
       "7     74215  윤석민  16000만원\n",
       "8     64300  김하성  16000만원\n",
       "9     79130  강지광   2700만원\n",
       "10    63360  장시윤   3300만원\n",
       "11    79365  박동원  14000만원\n",
       "12    62332  김재현   4400만원\n",
       "13    76368  유재신   6000만원\n",
       "14    65357  송성문   3000만원\n",
       "15    79356  박헌도   8000만원\n",
       "16    76322  유선정   3900만원\n",
       "17    61363  문우람   9000만원\n",
       "18    79300  김지수   5500만원\n",
       "19    73606  서동욱   5800만원\n",
       "20    64346  임병욱   4000만원\n",
       "21    79334  장영석   3300만원\n",
       "22    63339  김민준   2700만원\n",
       "23    65343  김택형   4400만원\n",
       "24    72749  마정길  20000만원\n",
       "25    60336  문성현  11000만원\n",
       "26    75321  손승락  70000만원\n",
       "27    62363  한현희  30000만원"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawling_player_info(33, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge_csv files in the path to new_file\n",
    "def concat_csv(path, new_file_name):\n",
    "    path = path\n",
    "    allfiles = glob.glob(os.path.join(path + \"*.csv\"))\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in allfiles:\n",
    "        df = pd.read_csv(file_, index_col=None, header=0)\n",
    "        list_.append(df)\n",
    "        \n",
    "    concat_df = pd.concat(list_, ignore_index=True)\n",
    "    concat_df.to_csv(new_file_name)\n",
    "    print(\"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
