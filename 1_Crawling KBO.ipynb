{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Crawling KBO\n",
    "\n",
    "- Website : http://www.koreabaseball.com\n",
    "- Object : 2015 season /  all 10 teams in KBO League\n",
    "- Player game stats\n",
    "    - hitter\n",
    "    - pitcher\n",
    "    - defense\n",
    "    - runner\n",
    "    \n",
    "- Player basic info\n",
    "    - salary and other basic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make api delay term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_delay_term = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Players' stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# crawling_hitter_basic_stats\n",
    "def crawling_hitter_basic(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    \n",
    "    # connect url\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "\n",
    "    # make empty dataframe\n",
    "    hitter_basic_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'avg', 'g', 'pa', 'ab', 'r', 'h', '2b',\n",
    "        '3b', 'hr', 'tb', 'rbi', 'sac', 'sf'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "\n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'g' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'pa' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'ab' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'r' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'h' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                '2b' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                '3b' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'hr' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'tb' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'rbi' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'sac' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'sf' : element.find_elements_by_css_selector('td')[15].text,\n",
    "            }\n",
    "            hitter_basic_df.loc[len(hitter_basic_df)] = tmp_dict\n",
    "    \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'g' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'pa' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'ab' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'r' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'h' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    '2b' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    '3b' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'hr' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'tb' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'rbi' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'sac' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'sf' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                }\n",
    "                hitter_basic_df.loc[len(hitter_basic_df)] = tmp_dict\n",
    "                \n",
    "    return hitter_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_hitter_detail_stats\n",
    "def crawling_hitter_detail(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/HitterBasic/Detail1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    hitter_detail_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'avg', 'xbh', 'go', 'ao', 'go/ao', 'gw rbi',\n",
    "        'bb/k', 'p/pa', 'isop', 'xr', 'gpa'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "    \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'xbh' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'go' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'ao' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'go/ao' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'gw rbi' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'bb/k' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'p/pa' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'isop' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'xr' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'gpa' : element.find_elements_by_css_selector('td')[13].text,\n",
    "            }\n",
    "            hitter_detail_df.loc[len(hitter_detail_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'avg' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'xbh' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'go' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'ao' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'go/ao' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'gw rbi' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'bb/k' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'p/pa' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'isop' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'xr' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'gpa' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                }\n",
    "                hitter_detail_df.loc[len(hitter_detail_df)] = tmp_dict\n",
    "                \n",
    "    return hitter_detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_pitcher_basic\n",
    "def crawling_pitcher_basic(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    pitcher_basic_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'ERA', 'G', 'W', 'L', 'SV', 'HLD', 'WPCT',\n",
    "        'IP', 'H', 'HR', 'BB', 'HBP', 'SO', 'R', 'ER', 'WHIP'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'W' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'L' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'SV' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'HLD' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'WPCT' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'IP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'H' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'HR' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'BB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'HBP' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'SO' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                'R' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                'ER' : element.find_elements_by_css_selector('td')[17].text,\n",
    "                'WHIP' : element.find_elements_by_css_selector('td')[18].text,\n",
    "            }\n",
    "            pitcher_basic_df.loc[len(pitcher_basic_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'W' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'L' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'SV' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'HLD' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'WPCT' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'IP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'H' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'HR' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'BB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'HBP' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'SO' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                    'R' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                    'ER' : element.find_elements_by_css_selector('td')[17].text,\n",
    "                    'WHIP' : element.find_elements_by_css_selector('td')[18].text,\n",
    "                }\n",
    "                pitcher_basic_df.loc[len(pitcher_basic_df)] = tmp_dict\n",
    "        \n",
    "    return pitcher_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_pitcher_detail\n",
    "def crawling_pitcher_detail(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 1982 ~ 34 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/PitcherBasic/Detail1.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    pitcher_detail_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'ERA', 'GS', 'Wgs', 'Wgr', 'GF', 'SVO', 'TS',\n",
    "        'GDP', 'GO', 'AO', 'GO/AO'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'GS' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'Wgs' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'Wgr' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'GF' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'SVO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'TS' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'GDP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'GO' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'AO' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'GO/AO' : element.find_elements_by_css_selector('td')[13].text,\n",
    "            }\n",
    "            pitcher_detail_df.loc[len(pitcher_detail_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'ERA' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'GS' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'Wgs' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'Wgr' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'GF' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'SVO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'TS' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'GDP' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'GO' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'AO' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'GO/AO' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                }\n",
    "                pitcher_detail_df.loc[len(pitcher_detail_df)] = tmp_dict\n",
    "    return pitcher_detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_defense\n",
    "def crawling_defense(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 14\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 2002 ~ 14 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/Defense/Basic.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    defense_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'POS', 'G', 'GS', 'IP', 'E', 'PKO', 'PO',\n",
    "        'A', 'DP', 'FPCT', 'PB', 'SB', 'CS', 'CS%'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'POS' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'GS' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'IP' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'E' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'PKO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'PO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                'A' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                'DP' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                'FPCT' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                'PB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                'SB' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                'CS' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                'CS%' : element.find_elements_by_css_selector('td')[16].text,\n",
    "            }\n",
    "            defense_df.loc[len(defense_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'POS' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'GS' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'IP' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'E' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'PKO' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'PO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                    'A' : element.find_elements_by_css_selector('td')[10].text,\n",
    "                    'DP' : element.find_elements_by_css_selector('td')[11].text,\n",
    "                    'FPCT' : element.find_elements_by_css_selector('td')[12].text,\n",
    "                    'PB' : element.find_elements_by_css_selector('td')[13].text,\n",
    "                    'SB' : element.find_elements_by_css_selector('td')[14].text,\n",
    "                    'CS' : element.find_elements_by_css_selector('td')[15].text,\n",
    "                    'CS%' : element.find_elements_by_css_selector('td')[16].text,\n",
    "                }\n",
    "                defense_df.loc[len(defense_df)] = tmp_dict\n",
    "\n",
    "    return defense_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crawling_runner\n",
    "def crawling_runner(season_id, team_id):\n",
    "    \"\"\"\n",
    "    season_id = 0 ~ 34\n",
    "    team_id = 1 ~ 10\n",
    "    ------------------------------------------------------------------------------------\n",
    "    <season_id>\n",
    "    0 : 2002 ~ 14 : 2016\n",
    "    \n",
    "    <team_id> ==> It can be different from several season.\n",
    "    1 : Nexen heroes\n",
    "    2 : Doosan\n",
    "    3 : Lotte\n",
    "    4 : Samsung\n",
    "    5 : Hanhwa\n",
    "    6 : KIA\n",
    "    7 : KT\n",
    "    8 : LG twins\n",
    "    9 : NC dinos\n",
    "    10 : SK wyberns\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/Runner/Basic.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "            find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "            find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "        \n",
    "    # make empty dataframe\n",
    "    runner_df = pd.DataFrame(columns=[\n",
    "        'rank', 'name', 'team', 'G', 'SBA', 'SB', 'CS', 'SB%', 'OOB',\n",
    "        'PKO'\n",
    "    ])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "        \n",
    "        for element in elements:\n",
    "            tmp_dict  = {\n",
    "                'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                'G' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                'SBA' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                'SB' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                'CS' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                'SB%' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                'OOB' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                'PKO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "            }\n",
    "            runner_df.loc[len(runner_df)] = tmp_dict\n",
    "        \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict  = {\n",
    "                    'rank' : element.find_elements_by_css_selector('td')[0].text,\n",
    "                    'name' : element.find_elements_by_css_selector('td')[1].text,\n",
    "                    'team' : element.find_elements_by_css_selector('td')[2].text,\n",
    "                    'G' : element.find_elements_by_css_selector('td')[3].text,\n",
    "                    'SBA' : element.find_elements_by_css_selector('td')[4].text,\n",
    "                    'SB' : element.find_elements_by_css_selector('td')[5].text,\n",
    "                    'CS' : element.find_elements_by_css_selector('td')[6].text,\n",
    "                    'SB%' : element.find_elements_by_css_selector('td')[7].text,\n",
    "                    'OOB' : element.find_elements_by_css_selector('td')[8].text,\n",
    "                    'PKO' : element.find_elements_by_css_selector('td')[9].text,\n",
    "                }\n",
    "                runner_df.loc[len(runner_df)] = tmp_dict\n",
    "\n",
    "    return runner_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Players' Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save player url\n",
    "def get_players_url(season_id, team_id):\n",
    "    # connect url\n",
    "    url = \"http://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    driver.get(url)\n",
    "    \n",
    "    # click season\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlSeason_ddlSeason').\\\n",
    "                find_elements_by_css_selector('option')[season_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # click team\n",
    "    driver.find_element_by_css_selector('#cphContainer_cphContents_ddlTeam_ddlTeam').\\\n",
    "                find_elements_by_css_selector('option')[team_id].click()\n",
    "    time.sleep(api_delay_term)\n",
    "    \n",
    "    # get page number\n",
    "    page_elements = driver.find_elements_by_css_selector(\".paging02 a\")\n",
    "    page_number = len(page_elements)\n",
    "    if page_number == 1:\n",
    "        page_number = page_number\n",
    "    \n",
    "    if page_number > 1:\n",
    "        page_number = page_number -2\n",
    "    \n",
    "    # make empty dataframe\n",
    "    url_df = pd.DataFrame(columns=['url'])\n",
    "    \n",
    "    # if having one page\n",
    "    if page_number == 1:\n",
    "        elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "        elements = elements[1:len(elements)+1]\n",
    "    \n",
    "        for element in elements:\n",
    "            tmp_dict = {\n",
    "                \"url\" : element.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "                }\n",
    "            url_df.loc[len(url_df)] = tmp_dict\n",
    "            \n",
    "    # if having other more pages\n",
    "    if page_number > 1:\n",
    "        for page in range(1, page_number+1):\n",
    "            driver.find_element_by_css_selector('#cphContainer_cphContents_ucPager_btnNo' + str(page)).click()\n",
    "            time.sleep(api_delay_term)\n",
    "            \n",
    "            elements = driver.find_elements_by_css_selector(\".record_result tr\")\n",
    "            elements = elements[1:len(elements)+1]\n",
    "            \n",
    "            for element in elements:\n",
    "                tmp_dict = {\n",
    "                    \"url\" : element.find_element_by_css_selector(\"a\").get_attribute(\"href\")\n",
    "                    }\n",
    "                url_df.loc[len(url_df)] = tmp_dict\n",
    "            \n",
    "    return url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawling_player_info(season_id, team_id):\n",
    "    # get each player's url\n",
    "    url_df = get_players_url(season_id, team_id)\n",
    "    \n",
    "    # drop the retired players\n",
    "    is_retired = url_df['url'].str.contains(\"Retire\") == True\n",
    "    url_df = url_df.drop(url_df.index[is_retired]).reset_index()\n",
    "    print(\"get url_df successfully\")\n",
    "    \n",
    "    # make empty dataframe\n",
    "    player_info_df = pd.DataFrame(columns=[\n",
    "                    \"p_number\", \"name\", \"salary\", \"entry_yr\"\n",
    "            ])\n",
    "    driver1 = webdriver.PhantomJS()\n",
    "    \n",
    "    # connect each url & scrap player info\n",
    "    for number in range(0, len(url_df)):\n",
    "        player_url = url_df['url'][number]\n",
    "        driver1.get(player_url)\n",
    "        time.sleep(api_delay_term)\n",
    "        \n",
    "        player_info = driver1.find_elements_by_css_selector(\".player_basic ul li\")\n",
    "\n",
    "        tmp_dict = {\n",
    "                    \"p_number\" : player_url.split(\"=\")[1],\n",
    "                    \"name\" : player_info[0].text.split(\": \")[1],\n",
    "                    \"salary\" : player_info[7].text.split(\": \")[1],\n",
    "                    \"entry_yr\" : player_info[9].text.split(\": \")[1]\n",
    "                    }\n",
    "        player_info_df.loc[len(player_info_df)] = tmp_dict\n",
    "\n",
    "    return player_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_hitter_pitcher_salary(team_name):\n",
    "    # read files\n",
    "    hsalary = pd.read_csv('./' + team_name + '_hsalary')\n",
    "    psalary = pd.read_csv('./' + team_name + '_psalary')\n",
    "    \n",
    "    # concat and preprocess\n",
    "    concat_salary = pd.concat([hsalary, psalary], axis=0).reset_index()\n",
    "    concat_salary['team'] = team_name\n",
    "    concat_salary = concat_salary.drop(['index', 'Unnamed: 0'], axis=1)\n",
    "    \n",
    "    # save the concatanated file\n",
    "    concat_salary.to_csv('./salary/' + team_name + '.csv', encoding='utf8')\n",
    "    \n",
    "    return concat_salary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge_csv files in the path to new_file\n",
    "def concat_csv(path, new_file_name):\n",
    "    path = path\n",
    "    allfiles = glob.glob(os.path.join(path + \"*.csv\"))\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in allfiles:\n",
    "        df = pd.read_csv(file_, index_col=None, header=0)\n",
    "        list_.append(df)\n",
    "        \n",
    "    concat_df = pd.concat(list_, ignore_index=True)\n",
    "    concat_df.to_csv(path + new_file_name, encoding='utf8')\n",
    "    print(\"success\")\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(dollar) * 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_won = kia_salary[\"salary\"].str.contains(\"만원\") == True\n",
    "won = kia_salary[is_won].loc[0]['salary'].split('만원')[0]\n",
    "int(won) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
